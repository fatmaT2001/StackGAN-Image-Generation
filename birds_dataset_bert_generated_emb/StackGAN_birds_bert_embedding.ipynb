{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4845244,"sourceType":"datasetVersion","datasetId":2808179},{"sourceId":5140550,"sourceType":"datasetVersion","datasetId":2534241},{"sourceId":8446611,"sourceType":"datasetVersion","datasetId":5033111}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install numpy pillow pandas tensorflow keras matplotlib torch gensim","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:34:35.833217Z","iopub.execute_input":"2024-05-22T03:34:35.834090Z","iopub.status.idle":"2024-05-22T03:34:53.968693Z","shell.execute_reply.started":"2024-05-22T03:34:35.834055Z","shell.execute_reply":"2024-05-22T03:34:53.967573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport pandas as pd \nimport torch\nfrom transformers import BertTokenizer, BertModel,pipeline\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport time\nimport PIL\nimport tensorflow as tf\nfrom PIL import Image\nfrom keras import Input, Model\nfrom keras import backend as K\nfrom keras.callbacks import TensorBoard\nfrom keras.layers import Dense, LeakyReLU, BatchNormalization, ReLU, Reshape, UpSampling2D, Conv2D, Activation, \\\n    concatenate, Flatten, Lambda, Concatenate\nfrom keras.optimizers import Adam\nfrom matplotlib import pyplot as plt\nimport pickle\nimport os\nimport random\nimport torch\nimport torch.nn as nn\nfrom torchvision import transforms\nimport ast\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:34:53.970493Z","iopub.execute_input":"2024-05-22T03:34:53.970798Z","iopub.status.idle":"2024-05-22T03:34:54.304866Z","shell.execute_reply.started":"2024-05-22T03:34:53.970771Z","shell.execute_reply":"2024-05-22T03:34:54.303904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Embedding Layer For CUB2002011**","metadata":{}},{"cell_type":"markdown","source":"Extract The Caption Of Each Image ","metadata":{}},{"cell_type":"code","source":"# os.mkdir(\"/kaggle/working/results\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:34:54.306254Z","iopub.execute_input":"2024-05-22T03:34:54.306683Z","iopub.status.idle":"2024-05-22T03:34:54.310603Z","shell.execute_reply.started":"2024-05-22T03:34:54.306643Z","shell.execute_reply":"2024-05-22T03:34:54.309720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def load_text(text_file_path):\n#     \"\"\"\n#     Load text from a file and return it as a string.\n#     \"\"\"\n#     with open(text_file_path, 'r', encoding='utf-8') as file:\n#         text = file.read().strip().split('\\n')\n#     return text\n\n# def load_class_ids(class_info_file_path):\n#     \"\"\"\n#     Load class ids from class_info.pickle file\n#     \"\"\"\n#     with open(class_info_file_path, 'rb') as f:\n#         class_ids = pickle.load(f, encoding='latin1')\n#         return class_ids\n      \n# def load_embeddings(embeddings_file_path):\n#     \"\"\"\n#     Load embeddings\n#     \"\"\"\n#     with open(embeddings_file_path, 'rb') as f:\n#         embeddings = pickle.load(f, encoding='latin1')\n#         embeddings = np.array(embeddings)\n#         print('embeddings: ', embeddings.shape)\n#     return embeddings\n \n# def load_filenames(filenames_file_path):\n#     \"\"\"\n#     Load filenames.pickle file and return a list of all file names\n#     \"\"\"\n#     with open(filenames_file_path, 'rb') as f:\n#         filenames = pickle.load(f, encoding='latin1')\n#     return filenames\n \n\n\n# def load_bounding_boxes(dataset_dir):\n#     \"\"\"\n#     Load bounding boxes and return a dictionary of file names and corresponding bounding boxes\n#     \"\"\"\n#     # Paths\n#     bounding_boxes_path = os.path.join(dataset_dir, 'bounding_boxes.txt')\n#     file_paths_path = os.path.join(dataset_dir, 'images.txt')\n\n#     # Read bounding_boxes.txt and images.txt file\n#     df_bounding_boxes = pd.read_csv(bounding_boxes_path,\n#                                     delim_whitespace=True, header=None).astype(int)\n#     df_file_names = pd.read_csv(file_paths_path, delim_whitespace=True, header=None)\n\n#     # Create a list of file names\n#     file_names = df_file_names[1].tolist()\n\n#     # Create a dictionary of file_names and bounding boxes\n#     filename_boundingbox_dict = {img_file[:-4]: [] for img_file in file_names[:2]}\n\n#     # Assign a bounding box to the corresponding image\n#     for i in range(0, len(file_names)):\n#         # Get the bounding box\n#         bounding_box = df_bounding_boxes.iloc[i][1:].tolist()\n#         key = file_names[i][:-4]\n#         filename_boundingbox_dict[key] = bounding_box\n\n#     return filename_boundingbox_dict\n\n\n# def get_img(img_path, bbox, image_size):\n#     \"\"\"\n#     Load and resize image\n#     \"\"\"\n#     img = Image.open(img_path).convert('RGB')\n#     width, height = img.size\n#     if bbox is not None:\n#         R = int(np.maximum(bbox[2], bbox[3]) * 0.75)\n#         center_x = int((2 * bbox[0] + bbox[2]) / 2)\n#         center_y = int((2 * bbox[1] + bbox[3]) / 2)\n#         y1 = np.maximum(0, center_y - R)\n#         y2 = np.minimum(height, center_y + R)\n#         x1 = np.maximum(0, center_x - R)\n#         x2 = np.minimum(width, center_x + R)\n#         img = img.crop([x1, y1, x2, y2])\n#     img = img.resize(image_size, PIL.Image.BILINEAR)\n#     return img\n# def load_dataset(filenames_file_path, class_info_file_path, cub_dataset_dir,text_dir, embeddings_file_path, image_size):\n#     \"\"\"\n#     Load dataset\n#     \"\"\"\n#     filenames = load_filenames(filenames_file_path)\n#     class_ids = load_class_ids(class_info_file_path)\n#     bounding_boxes = load_bounding_boxes(cub_dataset_dir)\n#     all_embeddings = load_embeddings(embeddings_file_path)\n#     X, y, embeddings,texts = [], [], [],[]\n\n#     print(\"Embeddings shape:\", all_embeddings.shape)\n\n#     for index, filename in enumerate(filenames):\n#         bounding_box = bounding_boxes[filename]\n        \n\n#         try:\n#             # Load images\n#             img_name = '{}/images/{}.jpg'.format(cub_dataset_dir, filename)\n#             text_file= load_text('{}/text_c10/{}.txt'.format(text_dir, filename))\n#             img = get_img(img_name, bounding_box, image_size)\n#             all_embeddings1 = all_embeddings[index, :, :]\n\n#             embedding_ix = random.randint(0, all_embeddings1.shape[0] - 1)\n#             embedding = all_embeddings1[embedding_ix, :]\n#             text=text_file[embedding_ix]\n\n#             X.append(np.array(img))\n#             y.append(class_ids[index])\n#             embeddings.append(embedding)\n#             texts.append(text)\n#         except Exception as e:\n#             print(e)\n\n#     X = np.array(X)\n#     y = np.array(y)\n#     embeddings = np.array(embeddings)\n    \n#     return X, y, embeddings,text","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:34:54.312817Z","iopub.execute_input":"2024-05-22T03:34:54.313088Z","iopub.status.idle":"2024-05-22T03:34:54.321631Z","shell.execute_reply.started":"2024-05-22T03:34:54.313065Z","shell.execute_reply":"2024-05-22T03:34:54.320783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_image, train_label, train_embedding,train_text=load_dataset(\"/kaggle/working/data/birds/train/filenames.pickle\",\"/kaggle/working/data/birds/train/class_info.pickle\",\"/kaggle/input/cub2002011/CUB_200_2011\",\"/kaggle/input/cub2002011/cvpr2016_cub\",\"/kaggle/working/data/birds/train/char-CNN-RNN-embeddings.pickle\",(64,64))","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:34:54.322690Z","iopub.execute_input":"2024-05-22T03:34:54.323006Z","iopub.status.idle":"2024-05-22T03:34:54.336403Z","shell.execute_reply.started":"2024-05-22T03:34:54.322977Z","shell.execute_reply":"2024-05-22T03:34:54.335400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_image, test_label, test_embedding,test_text=load_dataset(\"/kaggle/working/data/birds/test/filenames.pickle\",\"/kaggle/working/data/birds/test/class_info.pickle\",\"/kaggle/input/cub2002011/CUB_200_2011\",\"/kaggle/input/cub2002011/cvpr2016_cub\",\"/kaggle/working/data/birds/test/char-CNN-RNN-embeddings.pickle\",(64,64)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:34:54.337618Z","iopub.execute_input":"2024-05-22T03:34:54.337931Z","iopub.status.idle":"2024-05-22T03:34:54.346851Z","shell.execute_reply.started":"2024-05-22T03:34:54.337908Z","shell.execute_reply":"2024-05-22T03:34:54.345847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_df=pd.DataFrame({\n#     \"image\":list(train_image),\n#     \"train_text\":train_text,\n#     \"vector_emb\":list(train_embedding)\n# })\n# train_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:34:54.349012Z","iopub.execute_input":"2024-05-22T03:34:54.349567Z","iopub.status.idle":"2024-05-22T03:34:54.358519Z","shell.execute_reply.started":"2024-05-22T03:34:54.349536Z","shell.execute_reply":"2024-05-22T03:34:54.357633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_df=pd.DataFrame({\n#     \"image\":list(test_image),\n#     \"train_text\":test_text,\n#     \"vector_emb\":list(test_embedding)\n# })\n# test_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:34:54.359645Z","iopub.execute_input":"2024-05-22T03:34:54.359905Z","iopub.status.idle":"2024-05-22T03:34:54.368791Z","shell.execute_reply.started":"2024-05-22T03:34:54.359883Z","shell.execute_reply":"2024-05-22T03:34:54.367992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_pickle('/kaggle/input/birds-embedding/test_data.pkl')\ntrain_df = pd.read_pickle('/kaggle/input/birds-embedding/train_data.pkl')\n\ntest_df.drop(columns=\"vector_emb\",inplace=True)\ntrain_df.drop(columns=\"vector_emb\",inplace=True)\n\ntrain_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:34:54.369793Z","iopub.execute_input":"2024-05-22T03:34:54.370050Z","iopub.status.idle":"2024-05-22T03:35:02.732623Z","shell.execute_reply.started":"2024-05-22T03:34:54.370029Z","shell.execute_reply":"2024-05-22T03:35:02.731673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Generate Embedding**","metadata":{}},{"cell_type":"code","source":"# Initialize the BERT pipeline for feature extraction\nembedder = pipeline('feature-extraction', model='bert-base-uncased', tokenizer='bert-base-uncased')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:35:02.735889Z","iopub.execute_input":"2024-05-22T03:35:02.736179Z","iopub.status.idle":"2024-05-22T03:35:07.573101Z","shell.execute_reply.started":"2024-05-22T03:35:02.736155Z","shell.execute_reply":"2024-05-22T03:35:07.572163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a function to get BERT embeddings\ndef get_bert_embedding(caption):\n    embedding = embedder(caption)\n    mean_embedding = np.mean(embedding[0], axis=0)\n    return mean_embedding","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:35:07.574435Z","iopub.execute_input":"2024-05-22T03:35:07.574776Z","iopub.status.idle":"2024-05-22T03:35:07.582614Z","shell.execute_reply.started":"2024-05-22T03:35:07.574748Z","shell.execute_reply":"2024-05-22T03:35:07.581171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assign the embeddings to a new column in the sampled dataframe\ntest_df['bert_vector'] = test_df['train_text'].apply(lambda x: get_bert_embedding(x))\ntest_df.to_csv('test_df_with_bert_embeddings.csv', index=False)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:35:07.584729Z","iopub.execute_input":"2024-05-22T03:35:07.585141Z","iopub.status.idle":"2024-05-22T03:39:40.434030Z","shell.execute_reply.started":"2024-05-22T03:35:07.585070Z","shell.execute_reply":"2024-05-22T03:39:40.432957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assign the embeddings to a new column in the sampled dataframe\ntrain_df['bert_vector'] = train_df['train_text'].apply(lambda x: get_bert_embedding(x))\ntrain_df.to_csv('train_df_with_bert_embeddings.csv', index=False)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:39:40.435771Z","iopub.execute_input":"2024-05-22T03:39:40.436211Z","iopub.status.idle":"2024-05-22T03:56:43.638301Z","shell.execute_reply.started":"2024-05-22T03:39:40.436170Z","shell.execute_reply":"2024-05-22T03:56:43.637251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Download Embedding Result From Drive**","metadata":{}},{"cell_type":"code","source":"# import requests\n# import zipfile\n# import os\n\n# url = 'https://github.com/brangerbriz/docker-StackGAN/releases/download/datasets/birds.zip'\n# response = requests.get(url)\n\n# if response.status_code == 200:\n#     # Write the zip file to local disk\n#     with open('birds.zip', 'wb') as f:\n#         f.write(response.content)\n    \n#     # Create a directory to unzip the files into\n#     os.makedirs('data', exist_ok=True)\n\n#     # Unzipping the file\n#     with zipfile.ZipFile('birds.zip', 'r') as zip_ref:\n#         zip_ref.extractall('data')\n#     print(\"Files unzipped successfully\")\n# else:\n#     print(\"Failed to retrieve the file\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:56:43.641127Z","iopub.execute_input":"2024-05-22T03:56:43.641429Z","iopub.status.idle":"2024-05-22T03:56:43.646372Z","shell.execute_reply.started":"2024-05-22T03:56:43.641405Z","shell.execute_reply":"2024-05-22T03:56:43.645281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Install required packages\n# !pip install rarfile\n# !apt-get install unrar\n# !pip install gdown\n\n# # Download the .rar file\n# !gdown --id 10R3ft9881CHK1MFPjShK1uE7-oYo7lu4\n\n# # Extract the .rar file\n# import rarfile\n# import os\n\n# # Define the path to the .rar file and the extraction path\n# rar_file_path = 'embedding_for_stackan.rar'\n# extract_path = 'embedding_for_stackan'\n\n# # Open the .rar file\n# with rarfile.RarFile(rar_file_path) as rf:\n#     rf.extractall(extract_path)\n\n# # List the extracted files\n# os.listdir(extract_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:58:44.094698Z","iopub.execute_input":"2024-05-22T03:58:44.095407Z","iopub.status.idle":"2024-05-22T03:58:44.100231Z","shell.execute_reply.started":"2024-05-22T03:58:44.095372Z","shell.execute_reply":"2024-05-22T03:58:44.099032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Conditioning Augmentation**","metadata":{}},{"cell_type":"code","source":"class CA_NET(nn.Module):\n    def __init__(self, embedding_text_dim=768, c_dim=128, device='cuda'):\n        super(CA_NET, self).__init__()\n        self.embedding_text_dim = embedding_text_dim\n        self.c_dim = c_dim\n        self.device = device  # Save device as a class attribute\n        self.fc = nn.Linear(embedding_text_dim, c_dim * 2, bias=True).to(self.device)\n        self.relu = nn.ReLU().to(self.device)\n            \n    def encode(self, text_embedding):\n        text_embedding = text_embedding.to(self.device)\n        x = self.relu(self.fc(text_embedding))  # reducing the text embedding dimension to 256 then using LRLU\n        mean = x[:, :self.c_dim]  # take the first 128 to be the mean\n        log_variance = x[:, self.c_dim:]  # take the last 128 to be the log variance\n        return mean, log_variance\n\n    def reparametrize(self, mean, log_variance):\n        std = log_variance.mul(0.5).exp_()  # calculating the std from the log_variance through taking the exp then the sqrt\n        eps = torch.randn_like(std)      \n        return eps.mul(std).add_(mean)  # create c: eps*std + mean\n        \n        \n    def forward(self, text_embedding):\n        mean, log_variance = self.encode(text_embedding)\n        c = self.reparametrize(mean, log_variance)\n        return c, mean, log_variance  # c (128,128)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:58:44.132333Z","iopub.execute_input":"2024-05-22T03:58:44.133003Z","iopub.status.idle":"2024-05-22T03:58:44.142430Z","shell.execute_reply.started":"2024-05-22T03:58:44.132973Z","shell.execute_reply":"2024-05-22T03:58:44.141421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Stage 1**","metadata":{}},{"cell_type":"code","source":"def conv3x3(in_planes, out_planes, stride=1):\n    \"3x3 convolution with padding\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\n# Upsale the spatial size by a factor of 2\ndef upBlock(in_planes, out_planes):\n    block = nn.Sequential(\n        nn.Upsample(scale_factor=2, mode='nearest'),\n        conv3x3(in_planes, out_planes),\n        nn.BatchNorm2d(out_planes),\n        nn.ReLU(True))\n    return block\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:58:44.148824Z","iopub.execute_input":"2024-05-22T03:58:44.149277Z","iopub.status.idle":"2024-05-22T03:58:44.155133Z","shell.execute_reply.started":"2024-05-22T03:58:44.149250Z","shell.execute_reply":"2024-05-22T03:58:44.154232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class D_GET_LOGITS(nn.Module):\n    def __init__(self, ndf, nef,device='cuda',bcondition=True):\n        super(D_GET_LOGITS, self).__init__()\n        self.df_dim = ndf #64\n        self.ef_dim = nef #128\n        self.bcondition = bcondition\n        self.device = device\n        if bcondition:\n            self.outlogits = nn.Sequential(\n                conv3x3(ndf * 8 + nef, ndf * 8), # 640 , 512\n                nn.BatchNorm2d(ndf * 8), \n                nn.LeakyReLU(0.2, inplace=True),\n                nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=4),\n                nn.Sigmoid()).to(self.device)\n        else:\n            self.outlogits = nn.Sequential(\n                nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=4),\n                nn.Sigmoid()).to(self.device)\n\n    def forward(self, h_code, c_code=None):\n        # conditioning output\n        if self.bcondition and c_code is not None:\n            c_code = c_code.view(-1, self.ef_dim, 1, 1)\n            c_code = c_code.repeat(1, 1, 4, 4)\n            # state size (ngf+egf) x 4 x 4\n            h_c_code = torch.cat((h_code, c_code), 1)\n\n        else:\n            h_c_code = h_code\n        output = self.outlogits(h_c_code)\n\n        return output.view(-1)\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:58:44.170340Z","iopub.execute_input":"2024-05-22T03:58:44.171129Z","iopub.status.idle":"2024-05-22T03:58:44.180546Z","shell.execute_reply.started":"2024-05-22T03:58:44.171104Z","shell.execute_reply":"2024-05-22T03:58:44.179469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Generative**","metadata":{}},{"cell_type":"code","source":"class STAGE1_G(nn.Module):\n    def __init__(self, device='cuda'):\n        super(STAGE1_G, self).__init__()\n        self.device = device\n        self.gf_dim = 128 * 8  # 128 * 8 = 1024\n        self.ef_dim = 128  # 128\n        self.z_dim = 100  # 100\n        self.define_module()\n\n    def define_module(self):\n        ninput = self.z_dim + self.ef_dim  # 100 + 128 = 228\n        ngf = self.gf_dim  # 1024\n        self.ca_net = CA_NET(device=self.device).to(self.device)\n\n        # -> ngf x 4 x 4 == 1024 x 4 x 4\n        self.fc = nn.Sequential(\n            nn.Linear(ninput, ngf * 4 * 4, bias=False),\n            nn.BatchNorm1d(ngf * 4 * 4),\n            nn.ReLU(True)).to(self.device)\n\n        # ngf x 4 x 4 -> ngf/2 x 8 x 8\n        self.upsample1 = upBlock(ngf, ngf // 2).to(self.device)\n        # -> ngf/4 x 16 x 16\n        self.upsample2 = upBlock(ngf // 2, ngf // 4).to(self.device)\n        # -> ngf/8 x 32 x 32\n        self.upsample3 = upBlock(ngf // 4, ngf // 8).to(self.device)\n        # -> ngf/16 x 64 x 64\n        self.upsample4 = upBlock(ngf // 8, ngf // 16).to(self.device)\n        # -> 3 x 64 x 64\n        self.img = nn.Sequential(\n            conv3x3(ngf // 16, 3),\n            nn.Tanh()).to(self.device)\n\n    def forward(self, text_embedding, noise):\n        \n        c_code, mu, logvar = self.ca_net(text_embedding)\n        z_c_code = torch.cat((noise, c_code), 1).to(self.device)\n        h_code = self.fc(z_c_code)\n\n        h_code = h_code.view(-1, self.gf_dim, 4, 4)\n        h_code = self.upsample1(h_code)\n        h_code = self.upsample2(h_code)\n        h_code = self.upsample3(h_code)\n        h_code = self.upsample4(h_code)\n        # state size 3 x 64 x 64\n        fake_img = self.img(h_code)\n        return fake_img, mu, logvar\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:58:44.200537Z","iopub.execute_input":"2024-05-22T03:58:44.201002Z","iopub.status.idle":"2024-05-22T03:58:44.212251Z","shell.execute_reply.started":"2024-05-22T03:58:44.200978Z","shell.execute_reply":"2024-05-22T03:58:44.211391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Discriminative**","metadata":{}},{"cell_type":"code","source":"class STAGE1_D(nn.Module):\n    def __init__(self, device='cuda'):\n        super(STAGE1_D, self).__init__()\n        self.device = device\n        self.df_dim = 64  # 64\n        self.ef_dim = 128  # 128\n        self.define_module()\n\n    def define_module(self):\n        ndf, nef = self.df_dim, self.ef_dim  # 64, 128\n        self.encode_img = nn.Sequential(\n            nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf) x 32 x 32\n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size (ndf*2) x 16 x 16\n            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size (ndf*4) x 8 x 8\n            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 8),\n            # state size (ndf * 8) x 4 x 4)\n            nn.LeakyReLU(0.2, inplace=True)\n        ).to(self.device)\n\n        self.get_cond_logits = D_GET_LOGITS(ndf, nef, device=self.device).to(self.device)  # 64, 128\n        self.get_uncond_logits = None\n\n    def forward(self, image):\n        img_embedding = self.encode_img(image)\n        return img_embedding\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:58:44.225514Z","iopub.execute_input":"2024-05-22T03:58:44.226121Z","iopub.status.idle":"2024-05-22T03:58:44.235210Z","shell.execute_reply.started":"2024-05-22T03:58:44.226097Z","shell.execute_reply":"2024-05-22T03:58:44.234397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def KL_loss(mu, logvar):\n    # Calculate the KL divergence\n    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)\n    return torch.mean(KLD)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:58:44.248561Z","iopub.execute_input":"2024-05-22T03:58:44.249083Z","iopub.status.idle":"2024-05-22T03:58:44.253394Z","shell.execute_reply.started":"2024-05-22T03:58:44.249057Z","shell.execute_reply":"2024-05-22T03:58:44.252474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Data Preperation**","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nfrom torchvision import transforms\n\nclass MyDataset(Dataset):\n    def __init__(self, dataframe, imsize=64, transform=None, target_transform=None):\n        self.transform = transform\n        self.target_transform = target_transform\n        self.imsize = imsize\n        self.data = dataframe\n\n    def get_img(self, image_data):\n        \"\"\"\n        Load and transform the image.\n        \"\"\"\n        if isinstance(image_data, str):\n            img = Image.open(image_data).convert('RGB')\n        elif isinstance(image_data, np.ndarray):\n            img = Image.fromarray(image_data)\n        else:\n            raise TypeError(\"Unsupported image data type.\")\n        \n        if self.transform is not None:\n            img = self.transform(img)\n        return img\n\n    def __getitem__(self, index):\n        row = self.data.iloc[index]\n        # Convert the string representation of the vector to a list of floats\n        vector = row['bert_vector']\n        # Convert to a numpy array\n#         vector = np.array([float(x) for x in vector_str.strip('[]').split() if x])\n        embedding = torch.tensor(vector, dtype=torch.float32)\n        img = self.get_img(row['image'])\n        if self.target_transform is not None:\n            embedding = self.target_transform(embedding)\n        comment = row['train_text']\n        return img, embedding, comment\n\n    def __len__(self):\n        return len(self.data)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:58:44.277669Z","iopub.execute_input":"2024-05-22T03:58:44.278174Z","iopub.status.idle":"2024-05-22T03:58:44.289413Z","shell.execute_reply.started":"2024-05-22T03:58:44.278150Z","shell.execute_reply":"2024-05-22T03:58:44.288226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:58:44.291425Z","iopub.execute_input":"2024-05-22T03:58:44.292570Z","iopub.status.idle":"2024-05-22T03:58:51.581402Z","shell.execute_reply.started":"2024-05-22T03:58:44.292507Z","shell.execute_reply":"2024-05-22T03:58:51.580309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the image transformations\ntransform = transforms.Compose([\n    transforms.RandomCrop(64),  # Randomly crop the image to the specified size\n    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally (data augmentation)\n    transforms.ToTensor(),  # Convert the image to a tensor\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n])\n\n\n# Create Dataset objects\ntrain_dataset =MyDataset(dataframe=train_df, transform=transform)\n\ntest_dataset = MyDataset(dataframe=test_df ,transform=transform)\n\n\n# Create DataLoader objects\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:58:51.583478Z","iopub.execute_input":"2024-05-22T03:58:51.583883Z","iopub.status.idle":"2024-05-22T03:58:51.592408Z","shell.execute_reply.started":"2024-05-22T03:58:51.583853Z","shell.execute_reply":"2024-05-22T03:58:51.591261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)\n    elif classname.find('Linear') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n        if m.bias is not None:\n            m.bias.data.fill_(0.0)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:58:51.593527Z","iopub.execute_input":"2024-05-22T03:58:51.593801Z","iopub.status.idle":"2024-05-22T03:58:51.609722Z","shell.execute_reply.started":"2024-05-22T03:58:51.593779Z","shell.execute_reply":"2024-05-22T03:58:51.608668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Training For The First 100 Epochs**","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Define the device\nnum_epochs = 100\nlr_decay_step = 600\ngenerator_lr = 2e-4\ndiscriminator_lr = 2e-4\n\n# Instantiate the networks\nGen1 = STAGE1_G(device=device)\nGen1.apply(weights_init)\nDis1 = STAGE1_D(device=device)\nDis1.apply(weights_init)\n\n# Define optimizers\nopt_d1 = torch.optim.Adam(Dis1.parameters(), lr=generator_lr, betas=(0.5, 0.999))\nopt_g1 = torch.optim.Adam(Gen1.parameters(), lr=discriminator_lr, betas=(0.5, 0.999))\n\n# Loss function\ncriterion = nn.BCELoss()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:58:51.612511Z","iopub.execute_input":"2024-05-22T03:58:51.613323Z","iopub.status.idle":"2024-05-22T03:58:51.789965Z","shell.execute_reply.started":"2024-05-22T03:58:51.613283Z","shell.execute_reply":"2024-05-22T03:58:51.789053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision\n\n# Function to denormalize and plot images\ndef denormalize(tensor):\n    tensor = tensor * 0.5 + 0.5  # Assuming the images were normalized to [-1, 1]\n    return tensor.clamp(0, 1)\n\ndef plot_images(images, epoch, nrow=4, title='Images', save=True):\n    images = denormalize(images)\n    grid_img = torchvision.utils.make_grid(images.cpu(), nrow=nrow, padding=2)\n    plt.figure(figsize=(15, 15))\n    plt.imshow(grid_img.permute(1, 2, 0))\n    plt.title(f'{title} at Epoch {epoch+1}')\n    plt.axis('off')\n    if save:\n        plt.savefig(f'/kaggle/working/results/generated_images_epoch_{epoch+1}.png') \n    plt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:58:51.791102Z","iopub.execute_input":"2024-05-22T03:58:51.791418Z","iopub.status.idle":"2024-05-22T03:58:51.798488Z","shell.execute_reply.started":"2024-05-22T03:58:51.791392Z","shell.execute_reply":"2024-05-22T03:58:51.797624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR\n\n\n# Initialize learning rate schedulers\nscheduler_g1 = StepLR(opt_g1, step_size=lr_decay_step, gamma=0.5)\nscheduler_d1 = StepLR(opt_d1, step_size=lr_decay_step, gamma=0.5)\n\nfor epoch in range(num_epochs):\n    D_loss = []\n    G_loss = []\n    \n    for real_img, real_embed ,comment in train_loader:\n        Gen1.train()  # Set the generator to training mode\n        Dis1.train()  # Set the discriminator to training mode\n    \n        # Move data to device\n        real_img = real_img.to(device)\n        real_embed = real_embed.to(device)\n\n        # Generate noise\n        noise_d = torch.randn(real_img.size(0), 100).to(device)\n        \n        # Train Discriminator\n        fake_img_disc, mean_d, var_d = Gen1(real_embed, noise_d)\n        fake_img_disc = fake_img_disc.detach()\n        mean_d = mean_d.detach()\n        var_d = var_d.detach()\n        \n        opt_d1.zero_grad()\n        \n        real_d1_feature = Dis1(real_img)\n        fake_d1_feature = Dis1(fake_img_disc)\n        \n        d1_real_op = Dis1.get_cond_logits(real_d1_feature, mean_d)\n        d1_fake_op = Dis1.get_cond_logits(fake_d1_feature, mean_d)\n        \n        wrong_mean_d = torch.roll(mean_d, 1, 0)\n        d1_mislabel_op = Dis1.get_cond_logits(real_d1_feature, wrong_mean_d)\n        \n        # Adjusting the real labels to be exactly 1\n        real_labels = torch.ones(d1_real_op.shape[0]).to(device)\n        fake_labels = torch.zeros(d1_fake_op.shape[0]).to(device)\n        \n        dloss_real = criterion(d1_real_op.squeeze(), real_labels)\n        dloss_fake = criterion(d1_fake_op.squeeze(), fake_labels)\n        dloss_mislabel = criterion(d1_mislabel_op.squeeze(), fake_labels)\n        dloss_total =dloss_real + 0.5 * (dloss_fake + dloss_mislabel)\n         \n        D_loss.append(dloss_total.item())\n        \n        dloss_total.backward()\n        opt_d1.step()\n        \n        # Train Generator\n        opt_g1.zero_grad()\n        \n        noise_g = torch.randn(real_img.size(0), 100).to(device)\n        fake_img_gen, mean_g, var_g = Gen1(real_embed, noise_g)\n        mean_gd = mean_g.detach()\n        \n        fake_img_g = Dis1(fake_img_gen)\n        g1_fake_op = Dis1.get_cond_logits(fake_img_g, mean_gd)\n        \n        real_labels = torch.ones(g1_fake_op.size()).to(device)\n        \n        gloss = criterion(g1_fake_op.squeeze(), real_labels)\n        kl_loss = KL_loss(mean_gd, var_d)\n        g_loss = gloss + kl_loss *  2.0\n        G_loss.append(gloss.item())\n    \n        gloss.backward()\n        opt_g1.step()\n\n    scheduler_g1.step()\n    scheduler_d1.step()\n    \n    print(f'Epoch [{epoch+1}/{num_epochs}], Discriminator Loss: {np.mean(D_loss)}, Generator Loss: {np.mean(G_loss)}')\n    #ploting real and generated images for each epoch \n    Gen1.eval()\n    if epoch%10==0:\n        with torch.no_grad():\n            noise = torch.randn(16, 100).to(device)  # Generate noise for 16 images\n            sample_embed = real_embed[:16]  # Use the first 16 embeddings\n\n            # Generate images\n            generated_images, _, _ = Gen1(sample_embed, noise)\n\n            # Plot real and generated images\n            plot_images(generated_images,epoch, title=f'Generated Images at Epoch {epoch+1}')","metadata":{"execution":{"iopub.status.busy":"2024-05-22T03:58:51.800025Z","iopub.execute_input":"2024-05-22T03:58:51.800310Z","iopub.status.idle":"2024-05-22T04:37:22.604252Z","shell.execute_reply.started":"2024-05-22T03:58:51.800287Z","shell.execute_reply":"2024-05-22T04:37:22.603269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model's state dictionary\ntorch.save(Gen1.state_dict(), 'stage1_gen_birds_generated_embedding.pth')\ntorch.save(Dis1.state_dict(), 'stage1_dis_birds_generated_embedding.pth')","metadata":{"execution":{"iopub.status.busy":"2024-05-22T04:37:22.605369Z","iopub.execute_input":"2024-05-22T04:37:22.605694Z","iopub.status.idle":"2024-05-22T04:37:22.787152Z","shell.execute_reply.started":"2024-05-22T04:37:22.605668Z","shell.execute_reply":"2024-05-22T04:37:22.785836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    noise = torch.randn(16, 100).to(device)  # Generate noise for 16 images\n    sample_embed = real_embed[:16]  # Use the first 16 embeddings\n\n    # Generate images\n    generated_images, _, _ = Gen1(sample_embed, noise)\n\n    # Plot real and generated images\n    plot_images(generated_images,epoch, title=f'Generated Images at Epoch {epoch+1}')","metadata":{"execution":{"iopub.status.busy":"2024-05-22T04:37:22.788911Z","iopub.execute_input":"2024-05-22T04:37:22.789462Z","iopub.status.idle":"2024-05-22T04:37:23.489430Z","shell.execute_reply.started":"2024-05-22T04:37:22.789418Z","shell.execute_reply":"2024-05-22T04:37:23.488428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"for epoch in range(100,100+num_epochs):\n    D_loss = []\n    G_loss = []\n    \n    for real_img, real_embed ,comment in train_loader:\n        Gen1.train()  # Set the generator to training mode\n        Dis1.train()  # Set the discriminator to training mode\n    \n        # Move data to device\n        real_img = real_img.to(device)\n        real_embed = real_embed.to(device)\n\n        # Generate noise\n        noise_d = torch.randn(real_img.size(0), 100).to(device)\n        \n        # Train Discriminator\n        fake_img_disc, mean_d, var_d = Gen1(real_embed, noise_d)\n        fake_img_disc = fake_img_disc.detach()\n        mean_d = mean_d.detach()\n        var_d = var_d.detach()\n        \n        opt_d1.zero_grad()\n        \n        real_d1_feature = Dis1(real_img)\n        fake_d1_feature = Dis1(fake_img_disc)\n        \n        d1_real_op = Dis1.get_cond_logits(real_d1_feature, mean_d)\n        d1_fake_op = Dis1.get_cond_logits(fake_d1_feature, mean_d)\n        \n        wrong_mean_d = torch.roll(mean_d, 1, 0)\n        d1_mislabel_op = Dis1.get_cond_logits(real_d1_feature, wrong_mean_d)\n        \n        # Adjusting the real labels to be exactly 1\n        real_labels = torch.ones(d1_real_op.shape[0]).to(device)\n        fake_labels = torch.zeros(d1_fake_op.shape[0]).to(device)\n        \n        dloss_real = criterion(d1_real_op.squeeze(), real_labels)\n        dloss_fake = criterion(d1_fake_op.squeeze(), fake_labels)\n        dloss_mislabel = criterion(d1_mislabel_op.squeeze(), fake_labels)\n        dloss_total =dloss_real + 0.5 * (dloss_fake + dloss_mislabel)\n         \n        D_loss.append(dloss_total.item())\n        \n        dloss_total.backward()\n        opt_d1.step()\n        \n        # Train Generator\n        opt_g1.zero_grad()\n        \n        noise_g = torch.randn(real_img.size(0), 100).to(device)\n        fake_img_gen, mean_g, var_g = Gen1(real_embed, noise_g)\n        mean_gd = mean_g.detach()\n        \n        fake_img_g = Dis1(fake_img_gen)\n        g1_fake_op = Dis1.get_cond_logits(fake_img_g, mean_gd)\n        \n        real_labels = torch.ones(g1_fake_op.size()).to(device)\n        \n        gloss = criterion(g1_fake_op.squeeze(), real_labels)\n        kl_loss = KL_loss(mean_gd, var_d)\n        g_loss = gloss + kl_loss *  2.0\n        G_loss.append(gloss.item())\n    \n        gloss.backward()\n        opt_g1.step()\n\n    scheduler_g1.step()\n    scheduler_d1.step()\n    \n    print(f'Epoch [{epoch+1}/{num_epochs}], Discriminator Loss: {np.mean(D_loss)}, Generator Loss: {np.mean(G_loss)}')\n    #ploting real and generated images for each epoch \n    Gen1.eval()\n    if epoch%10==0:\n        with torch.no_grad():\n            noise = torch.randn(16, 100).to(device)  # Generate noise for 16 images\n            sample_embed = real_embed[:16]  # Use the first 16 embeddings\n\n            # Generate images\n            generated_images, _, _ = Gen1(sample_embed, noise)\n\n            # Plot real and generated images\n            plot_images(generated_images,epoch, title=f'Generated Images at Epoch {epoch+1}')","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:32:53.836876Z","iopub.execute_input":"2024-05-22T09:32:53.837709Z","iopub.status.idle":"2024-05-22T10:09:49.195819Z","shell.execute_reply.started":"2024-05-22T09:32:53.837676Z","shell.execute_reply":"2024-05-22T10:09:49.194820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model's state dictionary\ntorch.save(Gen1.state_dict(), 'stage1_gen_birds_generated_embedding.pth')\ntorch.save(Dis1.state_dict(), 'stage1_dis_birds_generated_embedding.pth')","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:09:49.508284Z","iopub.execute_input":"2024-05-22T10:09:49.508694Z","iopub.status.idle":"2024-05-22T10:09:49.634660Z","shell.execute_reply.started":"2024-05-22T10:09:49.508660Z","shell.execute_reply":"2024-05-22T10:09:49.633627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generated_images_list = []\n\n# with torch.no_grad():\n#     for real_img,real_emb,comment in train_loader:\n#         # Generate a batch of noise\n#         noise_batch = torch.randn(real_img.size(0), 100).to(device)\n        \n        \n#         # Get the corresponding batch of embeddings\n#         sample_embed_batch = real_emb.to(device)\n        \n#         # Generate images for the current batch\n#         generated_images_batch, _, _ = Gen1(sample_embed_batch, noise_batch)\n        \n#         # Convert generated images to numpy arrays and add to the list\n#         for_ploting=generated_images_batch.cpu()\n#         generated_images_np_batch = denormalize(generated_images_batch.cpu())\n#         generated_images_list.extend(generated_images_np_batch.numpy())\n        \n# plot_images(for_ploting, title=f'Generated Images  {epoch+1}')\n","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_df['generated_images'] = generated_images_list\n# train_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T04:37:23.499179Z","iopub.execute_input":"2024-05-22T04:37:23.499483Z","iopub.status.idle":"2024-05-22T04:37:23.507254Z","shell.execute_reply.started":"2024-05-22T04:37:23.499460Z","shell.execute_reply":"2024-05-22T04:37:23.506197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pickle\n\n# # Exclude the last column and save the DataFrame\n# with open('/kaggle/working/train_data.pkl', 'wb') as file:\n#     pickle.dump(train_df.iloc[:, :-1], file)\n# # Exclude the last column and save the DataFrame\n# with open('/kaggle/working/test_data.pkl', 'wb') as file:\n#     pickle.dump(test_df, file)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T04:37:23.508436Z","iopub.execute_input":"2024-05-22T04:37:23.508732Z","iopub.status.idle":"2024-05-22T04:37:23.517289Z","shell.execute_reply.started":"2024-05-22T04:37:23.508708Z","shell.execute_reply":"2024-05-22T04:37:23.516397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Save the DataFrame as a pickle file\n# with open('/kaggle/working/train_data_after_stage1.pkl', 'wb') as file:\n#     pickle.dump(train_df, file)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T04:37:23.518664Z","iopub.execute_input":"2024-05-22T04:37:23.519408Z","iopub.status.idle":"2024-05-22T04:37:23.529269Z","shell.execute_reply.started":"2024-05-22T04:37:23.519327Z","shell.execute_reply":"2024-05-22T04:37:23.528137Z"},"trusted":true},"execution_count":null,"outputs":[]}]}